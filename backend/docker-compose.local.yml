```dockercompose
# LOCAL-ONLY: This compose file is for backend-only local development and
# testing. Prefer the repository root `docker-compose.yml` to run the full
# stack (Caddy, Authentik, Postgres, OpenWebUI, admin API, and backend).
# To run backend-only locally:
#   docker compose -f backend/docker-compose.local.yml up --build
services:

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama

  searxng:
    image: searxng/searxng:latest
    ports:
      - "8081:8080"
    volumes:
      - ./searxng:/etc/searxng

  rag-backend:
    build: ./backend_app
    environment:
      # Use the root-level postgres service (repo root docker-compose.yml)
      # Ensure AK_POSTGRES_* vars are set in the parent .env
      DATABASE_URL: postgresql+psycopg://${AK_POSTGRES_USER}:${AK_POSTGRES_PASSWORD}@postgres:5432/${AK_POSTGRES_DB}
      COLLECTION_DOCS: kb_docs
      COLLECTION_TOOLS: tool_catalog

      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_CHAT_MODEL: llama3.1
      OLLAMA_EMBED_MODEL: nomic-embed-text

      SEARXNG_URL: http://searxng:8080
      CDS_BASE_URL: https://cds.cern.ch
      INSPIRE_BASE_URL: https://inspirehep.net
      ARXIV_API_URL: http://export.arxiv.org/api/query

      TOOL_SELECT_TOPK: "6"
      FETCH_TIMEOUT_SECONDS: "25"
      MAX_CHARS_PER_DOC: "250000"
      MAX_URLS_PER_REQUEST: "30"
    ports:
      - "8000:8000"
    depends_on:
      - postgres
      - ollama
      - searxng

  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      ENABLE_FORWARD_USER_INFO_HEADERS: "true"
      DEFAULT_USER_ROLE: "user"
      WEBUI_SECRET_KEY: "change-me-please"
    volumes:
      - openwebui:/app/backend/data
    ports:
      - "3000:8080"
    depends_on:
      - ollama

volumes:
  pgdata:
  ollama:
  openwebui:

```
